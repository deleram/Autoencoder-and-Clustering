{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7725, 0.8902, 0.0863, 0.0353,\n",
      "        0.3255, 0.6549, 0.7765, 1.0000, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961,\n",
      "        0.6667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7686, 0.9922, 0.9922,\n",
      "        0.9922, 0.9922, 0.9922, 0.9725, 0.9294, 0.9059, 0.6039, 0.5647, 0.5020,\n",
      "        0.9922, 0.7647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.3098,\n",
      "        0.5725, 0.5725, 0.5725, 0.3804, 0.1725, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.2980, 0.9922, 0.7647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0196, 0.7529, 0.9647, 0.3569, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.1294, 0.9922, 0.7451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.2980, 0.9608, 0.2824, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.7294, 0.7569, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0902, 0.9725, 0.3255, 0.1333, 0.1176, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.4941, 0.9922, 0.9412, 0.7490, 0.0706,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.2000, 0.3216, 0.4392, 0.6627, 0.9843, 0.9490, 0.3608, 0.0157,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922, 0.9333, 0.8902,\n",
      "        0.9961, 0.9961, 0.9961, 0.9961, 0.9765, 0.9843, 0.9608, 0.3529, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0392, 0.2863,\n",
      "        0.3490, 0.6039, 0.5216, 0.3922, 0.2863, 0.1176, 0.9098, 0.8941, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1686, 0.9922, 0.6235,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7490, 0.9412,\n",
      "        0.0588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0549, 0.9961,\n",
      "        0.7725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3843,\n",
      "        0.9765, 0.1922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.8196, 0.9608, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.9608, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0863, 0.9725, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.2902, 0.8863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000])\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "\n",
    "dfPath = r'labeled_train_set.csv'\n",
    "trainData = pd.read_csv(dfPath)\n",
    "df = pd.DataFrame(trainData)\n",
    "df = df.iloc[:, 1:].values\n",
    "#transform values to pytorch tensor\n",
    "tensor_data = torch.tensor(df)\n",
    "#make them have values between 0 to 1\n",
    "normalized_tensor_data = tensor_data.float() / 255.0\n",
    "\n",
    "print(normalized_tensor_data[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#make a loader to enable us to iterate with batches of 32\n",
    "loader = torch.utils.data.DataLoader(dataset = normalized_tensor_data, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design our autoencoder\n",
    "\n",
    "# 28*28 -> 200 ->100 -> 50 -> 20 -> 10 -> 20 -> 50 -> 100 -> 200 -> 28*28\n",
    "# takes torch neural network as super set\n",
    "class AE(torch.nn.Module):\n",
    "# inherits init from torch.nn\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    # define encoder as sequence of layers you want and their activation functions\n",
    "    # We use ReLU as our activation function because it performed well in our last exercise, and \n",
    "    #it often performs well in neural networks. Additionally, due to its computational efficiency, it is a preferred choice\n",
    "\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28 * 28, 200),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(200, 100),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(100, 50),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(50, 20),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(20, 10)\n",
    "        )\n",
    "\n",
    "    #The decoder is the reverse of the encoder, and it has the same structure. \n",
    "    #Since we normalized the data, we use a sigmoid function at the end of the decoder to predict numbers within the range of [0, 1].\n",
    "\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 20),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(20, 50),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(50, 100),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(100, 200),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(200, 28 * 28),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    # we show the series of actions taken in our Autoencoder\n",
    "    # first we encode and then we decode\n",
    "    # the output is our answer\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = AE()\n",
    "\n",
    "#create an optimzer. we used adams as it's so widely used in nn\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3,  weight_decay = 1e-8)\n",
    "\n",
    "#beacuse our data is some how continues we use MSE as loss function\n",
    "# mean-squared error loss\n",
    "loss_function = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/50, loss = 0.000053\n",
      "epoch : 10/50, loss = 0.000050\n",
      "epoch : 20/50, loss = 0.000048\n",
      "epoch : 30/50, loss = 0.000058\n",
      "epoch : 40/50, loss = 0.000053\n",
      "epoch : 50/50, loss = 0.000060\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for batch_features in loader:\n",
    "        # reshape each batch\n",
    "        batch_features = batch_features.reshape(-1, 28*28)\n",
    "        \n",
    "        # reset the gradients for the new computations\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # calculate the output of our encoder\n",
    "        outputs = model(batch_features)\n",
    "        \n",
    "        # compute loss\n",
    "        loss = loss_function(outputs, batch_features)\n",
    "        \n",
    "        # perform backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        loss += loss.item()\n",
    "    \n",
    "    # Compute the epoch training loss\n",
    "    loss = loss / len(loader)\n",
    "    #print loss for 10*i th epoch\n",
    "    if(epoch%10 == 9 or epoch == 0):\n",
    "    # Display the epoch training loss\n",
    "        print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architectures and parameters are discussed in the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = next(iter(loader))\n",
    "for i, item in enumerate(image):\n",
    "    # Reshape the array for plotting\n",
    "    item = item.reshape(-1, 28, 28)\n",
    "    \n",
    "    # Convert the tensor to a NumPy array\n",
    "    item_np = item.detach().numpy()\n",
    "    \n",
    "    # Plot the image\n",
    "    plt.imshow(item_np[0])\n",
    "    plt.show()\n",
    "    \n",
    "    # Break out of the loop after plotting the first image\n",
    "    break\n",
    "\n",
    "for i, item in enumerate(model(image)):\n",
    "    item = item.reshape(-1, 28, 28)\n",
    "    \n",
    "    # Convert the tensor to a NumPy array\n",
    "    item_np = item.detach().numpy()\n",
    "    \n",
    "    # Plot the image\n",
    "    plt.imshow(item_np[0])\n",
    "    plt.show()\n",
    "    break\n",
    "# As you can see, after using the encoder, we obtained a significantly improved representation of the digits.\n",
    "# It can be considered as a denoising process. \n",
    "# Therefore, utilizing the autoencoder before classification assists in extracting enhanced features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we wanna apply the encoder on our data\n",
    "import numpy as np\n",
    "\n",
    "# Encode the data\n",
    "encoded_data = model.encoder(normalized_tensor_data)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "encoded_data_np = encoded_data.detach().numpy()\n",
    "labels_np = df[:, 0]  # Extract labels from the first column of df\n",
    "\n",
    "# Concatenate encoded data and labels\n",
    "data_with_labels = np.hstack((labels_np.reshape(-1, 1), encoded_data_np))\n",
    "\n",
    "# Create a DataFrame\n",
    "column_names = ['label'] + [f'feature{i+1}' for i in range(encoded_data_np.shape[1])]\n",
    "df_encoded = pd.DataFrame(data_with_labels, columns=column_names)\n",
    "\n",
    "# Save as CSV\n",
    "df_encoded.to_csv('encoded_data.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
